import os
import json
import pathlib
import shutil
import statistics
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
import requests


# =================== é…ç½® ===================
API_URL = "https://api.aring.cc/awakening-of-war-soul-ol/api/commerce/list"
DATA_FILE = "price_history.txt"
SITE_DIR = pathlib.Path("site")
TEMPLATE_FILE = pathlib.Path("app/templates/index.html")

CST = ZoneInfo("Asia/Shanghai")

COMMERCE_MAP = {
    1: "åœ°ç²¾é‡‘åº“",
    2: "å²è±å§†ä¿æŠ¤åä¼š",
    3: "ä¼ è¯´æ­¦åº“",
    4: "æ˜é’»å•†æˆ·",
    5: "é­”é¾™æ•™ä¼š",
}

HEADERS = {
    "Host": "api.aring.cc",
    "Origin": "https://aring.cc",
    "Accept-Encoding": "gzip, deflate, br",
    "Connection": "keep-alive",
    "Accept": "application/json, text/plain, */*",
    "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_2_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/134.0.6998.33 Mobile/15E148 Safari/604.1",
    "Accept-Language": "zh-CN,zh-Hans;q=0.9",
    "Referer": "https://aring.cc/",
    "token": os.getenv("ARING_TOKEN", ""),  # ä» Secrets æ³¨å…¥
}

# =================== æ—¶é—´å·¥å…· ===================
def now_cst():
    return datetime.now(CST)
SLOTS = [
    (10, 14, "10:00"),  # 10:00-13:59
    (14, 18, "14:00"),  # 14:00-17:59
    (18, 22, "18:00"),  # 18:00-21:59
    (22, 24, "22:00"),  # 22:00-23:59
]

def get_slot(now=None):
    """
    è¿”å› (slot_date_str, slot_label)
    22:00-09:59 å½’åˆ° 22:00 æ¡£ï¼›00:00-09:59 å½’åˆ°ã€å‰ä¸€å¤©ã€‘22:00 æ¡£ã€‚
    """
    if now is None:
        now = now_cst()
    h = now.hour
    # å‡Œæ™¨ 00:00-09:59 -> å‰ä¸€å¤© 22:00 æ¡£
    if h < 10:
        slot_date = (now - timedelta(days=1)).date()
        return slot_date.strftime("%Y/%m/%d"), "22:00"
    # ç™½å¤©æ®µæŒ‰è¡¨åŒ¹é…
    for start_h, end_h, label in SLOTS:
        if start_h <= h < end_h:
            return now.date().strftime("%Y/%m/%d"), label
    # ç†è®ºåˆ°ä¸äº†è¿™é‡Œï¼Œå…œåº•åˆ°å½“æ—¥ 22:00
    return now.date().strftime("%Y/%m/%d"), "22:00"

# =================== å†å²æ•°æ®è¯»å†™ ===================
def try_fetch_history_from_pages():
    """
    è¿è¡Œå¼€å§‹å‰ï¼Œå°è¯•ä»ä¸Šä¸€æ¬¡å‘å¸ƒçš„ Pages æ‹‰å›å†å²æ•°æ®ï¼Œä»¥ä¾¿è¿ç»­ç´¯è®¡ã€‚
    åœ¨ Actions ä¸­ä»¥ç¯å¢ƒå˜é‡ä¼ å…¥ï¼š
      HISTORY_URL=https://<user>.github.io/<repo>/price_history.txt
    """
    history_url = os.getenv("HISTORY_URL")
    if not history_url:
        return
    try:
        r = requests.get(history_url, timeout=10)
        if r.status_code == 200 and r.text.strip():
            with open(DATA_FILE, "w", encoding="utf-8") as f:
                f.write(r.text)
            print("âœ… å·²ä» Pages å–å›å†å²æ–‡ä»¶")
        else:
            print(f"â„¹ï¸ æœªä» Pages è·å–åˆ°å†å²ï¼ˆstatus={r.status_code}ï¼‰")
    except Exception as e:
        print(f"âš ï¸ æ‹‰å–å†å²å¤±è´¥ï¼š{e}")

def load_historical_data():
    """è¯»å–å†å² price_history.txtï¼Œè¿”å› {cid: [prices...]}"""
    hist = {cid: [] for cid in COMMERCE_MAP.keys()}
    if not os.path.exists(DATA_FILE):
        return hist
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        lines = [ln.strip() for ln in f.readlines() if ln.strip()]
    if not lines:
        return hist

    header = lines[0].split()
    expected_header = ["æ—¥æœŸ", "æ—¶é—´"] + [COMMERCE_MAP[cid] for cid in sorted(COMMERCE_MAP.keys())]
    if header != expected_header:
        print("âš ï¸ è¡¨å¤´ä¸åŒ¹é…ï¼Œå¿½ç•¥å†å²ã€‚")
        return hist

    for line in lines[1:]:
        parts = line.split()
        if len(parts) < 2 + len(COMMERCE_MAP):
            continue
        for idx, cid in enumerate(sorted(COMMERCE_MAP.keys()), start=2):
            try:
                price = float(parts[idx])
                hist[cid].append(price)
            except Exception:
                pass
    return hist

def save_data_row(current_date, time_slot, commerce_data):
    """å°†å½“å‰ä»·æ ¼è¿½åŠ åˆ°å†å²æ–‡ä»¶"""
    if not os.path.exists(DATA_FILE):
        with open(DATA_FILE, "w", encoding="utf-8") as f:
            header = "æ—¥æœŸ æ—¶é—´ " + " ".join(COMMERCE_MAP[cid] for cid in sorted(COMMERCE_MAP.keys()))
            f.write(header + "\n")

    last_line = None
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        lines = f.readlines()
        if len(lines) > 1:
            last_line = lines[-1].strip()

    if last_line:
        parts = last_line.split()
        if len(parts) >= 2:
            last_date, last_time = parts[0], parts[1]
            if last_date == current_date and last_time == time_slot:
                print(f"âš ï¸ {current_date} {time_slot} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜")
                return

    row = [current_date, time_slot] + [str(commerce_data.get(cid, 0)) for cid in sorted(COMMERCE_MAP.keys())]
    with open(DATA_FILE, "a", encoding="utf-8") as f:
        f.write(" ".join(row) + "\n")
    print("âœ… å·²è¿½åŠ åˆ° price_history.txt")

# =================== åˆ†æé€»è¾‘ï¼ˆæ¥è‡ªä½ åŸè„šæœ¬ï¼Œç•¥æœ‰æ•´ç†ï¼‰ ===================
def calculate_trend_analysis(prices):
    if len(prices) < 3:
        return {
            'short_trend': 'æ•°æ®ä¸è¶³', 'mid_trend': 'æ•°æ®ä¸è¶³',
            'trend_strength': 0, 'trend_description': 'æ•°æ®ä¸è¶³',
            'short_slope': 0, 'mid_slope': 0, 'prices': prices
        }

    recent_3 = prices[-3:]
    short_trend_slope = (recent_3[-1] - recent_3[0]) / 2 if len(recent_3) == 3 else 0

    mid_window = min(7, len(prices))
    recent_mid = prices[-mid_window:]
    mid_trend_slope = (recent_mid[-1] - recent_mid[0]) / (len(recent_mid) - 1) if len(recent_mid) >= 2 else 0

    price_range = max(prices) - min(prices)
    if price_range > 0:
        short_strength = abs(short_trend_slope) / price_range * 100
        mid_strength = abs(mid_trend_slope) / price_range * 100
    else:
        short_strength = mid_strength = 0

    def get_trend_direction(slope, strength):
        if strength < 0.5: return "æ¨ªç›˜"
        return "å¼ºåŠ¿ä¸Šå‡" if slope > 0 and strength > 2 else \
               "æ¸©å’Œä¸Šå‡" if slope > 0 else \
               "å¼ºåŠ¿ä¸‹é™" if slope < 0 and strength > 2 else "æ¸©å’Œä¸‹é™"

    short_direction = get_trend_direction(short_trend_slope, short_strength)
    mid_direction = get_trend_direction(mid_trend_slope, mid_strength)

    if short_direction == mid_direction:
        trend_desc = f"{mid_direction}ï¼Œè¶‹åŠ¿ç¨³å®š"
    elif "ä¸Šå‡" in mid_direction and "ä¸Šå‡" in short_direction:
        trend_desc = f"{mid_direction}ï¼ŒçŸ­æœŸåŠ é€Ÿ" if short_strength > mid_strength else f"{mid_direction}ï¼ŒçŸ­æœŸå‡é€Ÿ"
    elif "ä¸‹é™" in mid_direction and "ä¸‹é™" in short_direction:
        trend_desc = f"{mid_direction}ï¼ŒçŸ­æœŸåŠ é€Ÿ" if short_strength > mid_strength else f"{mid_direction}ï¼ŒçŸ­æœŸå‡é€Ÿ"
    elif ("ä¸Šå‡" in mid_direction and "ä¸‹é™" in short_direction) or ("ä¸‹é™" in mid_direction and "ä¸Šå‡" in short_direction):
        trend_desc = f"{mid_direction}ï¼ŒçŸ­æœŸåè½¬"
    else:
        trend_desc = f"ä¸­æœŸ{mid_direction}ï¼ŒçŸ­æœŸ{short_direction}"

    return {
        'short_trend': short_direction, 'mid_trend': mid_direction,
        'trend_strength': (short_strength + mid_strength) / 2,
        'trend_description': trend_desc, 'short_slope': short_trend_slope,
        'mid_slope': mid_trend_slope, 'prices': prices
    }

def calculate_price_analysis(current_price, historical_prices):
    if not historical_prices:
        return {'avg': current_price,'min': current_price,'max': current_price,
                'from_min_points': 0,'from_min_percent': 0,'from_max_points': 0,'from_max_percent': 0,
                'percentile': 50,'sample_size': 0}
    all_prices = historical_prices + [current_price]
    avg_price = statistics.mean(all_prices)
    min_price = min(all_prices); max_price = max(all_prices)
    from_min_points = current_price - min_price
    from_max_points = current_price - max_price
    price_range = max_price - min_price
    if price_range > 0:
        from_min_percent = (from_min_points / price_range) * 100
        from_max_percent = (from_max_points / price_range) * 100
    else:
        from_min_percent = from_max_percent = 0
    lower_count = sum(1 for p in all_prices if p < current_price)
    percentile = (lower_count / len(all_prices)) * 100
    return {
        'avg': avg_price,'min': min_price,'max': max_price,
        'from_min_points': from_min_points,'from_min_percent': from_min_percent,
        'from_max_points': from_max_points,'from_max_percent': from_max_percent,
        'percentile': percentile,'sample_size': len(historical_prices)
    }

def calculate_investment_advice(percentile, trend_analysis):
    if percentile <= 15: position_level = "æä½ä½"
    elif percentile <= 35: position_level = "ä½ä½"
    elif percentile <= 65: position_level = "ä¸­ä½"
    elif percentile <= 85: position_level = "é«˜ä½"
    else: position_level = "æé«˜ä½"

    position_score = 10 - (percentile / 10)  # 0%-100% -> 10-0

    mid_trend = trend_analysis['mid_trend']
    short_trend = trend_analysis['short_trend']
    desc = trend_analysis['trend_description']

    if "å¼ºåŠ¿ä¸Šå‡" in mid_trend: direction = 2
    elif "æ¸©å’Œä¸Šå‡" in mid_trend: direction = 1
    elif "æ¨ªç›˜" in mid_trend: direction = 0
    elif "æ¸©å’Œä¸‹é™" in mid_trend: direction = -1
    else: direction = -2

    is_reversing_up = "åè½¬" in desc and "ä¸Šå‡" in short_trend and direction < 0
    is_reversing_down = "åè½¬" in desc and "ä¸‹é™" in short_trend and direction > 0

    if percentile <= 15:
        if direction <= -1: trend_adj, reason = 5.0 + abs(direction)*2.0, "æä½ä½æ·±è·Œï¼Œå¼ºçƒˆä¹°å…¥ä¿¡å·"
        elif direction >= 1: trend_adj, reason = 4.5 + direction*1.5, "æä½ä½åå¼¹ï¼Œå¼ºçƒˆä¹°å…¥"
        else: trend_adj, reason = 4.0, "æä½ä½ç›˜æ•´ï¼Œå¼ºçƒˆä¹°å…¥"
    elif percentile <= 35:
        if direction <= -1: trend_adj, reason = 4.0 + abs(direction)*1.5, "ä½ä½æ·±è·Œï¼ŒæŠ„åº•è‰¯æœº"
        elif direction >= 1: trend_adj, reason = 3.5 + direction*1.2, "ä½ä½åå¼¹ï¼Œè¶‹åŠ¿å‘å¥½"
        else: trend_adj, reason = 3.0, "ä½ä½ç›˜æ•´ï¼Œå¯é€æ­¥å»ºä»“"
    elif 65 < percentile < 85:
        if direction >= 1: trend_adj, reason = (2.5 if direction==2 else 2.8), "é«˜ä½ä¸Šæ¶¨ï¼Œè°¨æ…æŒæœ‰"
        elif direction <= -1:
            if "åè½¬" in desc: trend_adj, reason = 1.5, "é«˜ä½å›è½ä½†å‡ºç°åè½¬ä¿¡å·ï¼Œè§‚æœ›ä¸ºä¸»"
            else: trend_adj, reason = -1.0 - abs(direction)*0.5, "é«˜ä½å›è½ï¼Œå»ºè®®å‡ä»“"
        else: trend_adj, reason = 1.8, "é«˜ä½ç›˜æ•´ï¼Œæ³¨æ„é£é™©"
    elif percentile >= 85:
        if direction >= 1: trend_adj, reason = -4.0 - direction*1.0, "æé«˜ä½è¿½æ¶¨ï¼Œé£é™©æå¤§"
        elif direction <= -1: trend_adj, reason = -2.0 - abs(direction)*0.8, "æé«˜ä½å›è½ï¼ŒåŠæ—¶æ­¢ç›ˆ"
        else: trend_adj, reason = -2.0, "æé«˜ä½ç›˜æ•´ï¼Œè­¦æƒ•å›è°ƒ"
    else:
        trend_adj = direction * 1.0
        reason = "ä¸­ä½ä¸Šæ¶¨ï¼Œå¯é€‚é‡å‚ä¸" if direction >= 1 else ("ä¸­ä½ä¸‹è·Œï¼Œæš‚æ—¶è§‚æœ›" if direction <= -1 else "ä¸­ä½ç›˜æ•´ï¼Œç­‰å¾…æ–¹å‘")

    if is_reversing_up:
        trend_adj += 2.0 if percentile <= 35 else (1.5 if percentile <= 65 else 1.0)
        reason = "ä½ä½æ­¢è·Œåå¼¹ï¼Œå¼ºçƒˆä¹°å…¥" if percentile <= 35 else ("ä¸­ä½æ­¢è·Œåå¼¹ï¼Œå¯é€‚é‡ä¹°å…¥" if percentile <= 65 else "é«˜ä½æ­¢è·Œåå¼¹ï¼Œè°¨æ…æŒæœ‰ï¼Œå¯é€‚å½“åŠ ä»“")
    elif is_reversing_down:
        trend_adj -= 2.0 if percentile >= 85 else (1.5 if percentile >= 65 else 0.5)
        reason = "æé«˜ä½å†²é«˜å›è½ï¼Œå¼ºçƒˆå–å‡º" if percentile >= 85 else ("é«˜ä½å†²é«˜å›è½ï¼Œå»ºè®®å‡ä»“" if percentile >= 65 else "ä¸­ä½ä½å†²é«˜å›è½ï¼Œæš‚æ—¶è§‚æœ›")

    final_score_internal = max(0, min(15, position_score + trend_adj))
    score_display = min(10, final_score_internal * 10 / 15)

    if score_display >= 8.5: advice, emoji, action = "ğŸ’°ğŸ’°ğŸ’°å¼ºçƒˆä¹°å…¥", "ğŸ’°ğŸ’°ğŸ’°", "æ»¡ä»“ä¹°å…¥"
    elif score_display >= 7.0: advice, emoji, action = "ğŸ’°ğŸ’°ä¹°å…¥", "ğŸ’°ğŸ’°", "é‡ä»“ä¹°å…¥"
    elif score_display >= 5.5: advice, emoji, action = "ğŸ’°å»ºè®®ä¹°å…¥", "ğŸ’°", "é€‚é‡ä¹°å…¥"
    elif score_display >= 4.5: advice, emoji, action = "ğŸ‘€è§‚æœ›ç­‰å¾…", "ğŸ‘€", "æš‚æ—¶è§‚æœ›"
    elif score_display >= 3.0: advice, emoji, action = "âš ï¸è°¨æ…æŒæœ‰", "âš ï¸", "è°¨æ…æŒæœ‰ï¼Œå¯é€‚å½“åŠ ä»“"
    elif score_display >= 2.0: advice, emoji, action = "ğŸ’¸å»ºè®®å–å‡º", "ğŸ’¸", "å»ºè®®å‡ä»“"
    elif score_display >= 1.0: advice, emoji, action = "ğŸ’¸ğŸ’¸å–å‡º", "ğŸ’¸ğŸ’¸", "é‡ä»“å‡ä»“"
    else: advice, emoji, action = "ğŸ’¸ğŸ’¸ğŸ’¸å¼ºçƒˆå–å‡º", "ğŸ’¸ğŸ’¸ğŸ’¸", "æ¸…ä»“ç¦»åœº"

    stars = "â­" * max(1, min(5, round(score_display / 2)))
    prices = trend_analysis.get('prices', [])
    confidence = "ä½" if len(prices) < 5 else ("ä¸­" if len(prices) < 15 else "é«˜")

    return {
        'advice': advice, 'advice_emoji': emoji, 'priority_score': score_display,
        'stars': stars, 'position_level': position_level, 'position_score': position_score,
        'trend_adjustment': trend_adj, 'trend_direction': direction, 'reason': reason,
        'action_desc': action, 'confidence': confidence
    }

def format_change_value(change):
    if change > 0: return f"+{change:.2f}ğŸ“ˆ"
    if change < 0: return f"{change:.2f}ğŸ“‰"
    return "0.00"

def format_analysis_text(commerce_name, current_price, change_value, analysis, trend_analysis, investment_advice):
    if analysis['percentile'] >= 80: level = "ğŸ”´é«˜ä½"
    elif analysis['percentile'] >= 60: level = "ğŸŸ¡ä¸­é«˜"
    elif analysis['percentile'] >= 40: level = "ğŸŸ¢ä¸­ä½"
    elif analysis['percentile'] >= 20: level = "ğŸ”µä¸­ä½"
    else: level = "âš«ä½ä½"

    change_str = format_change_value(change_value)
    s = []
    s.append(f"{commerce_name} {level}")
    s.append(f"ğŸ“Šå½“å‰ä»·æ ¼ï¼š{current_price:.2f} (å˜åŠ¨ï¼š{change_str})")
    s.append(f"ğŸ“…å†å²å‡ä»·ï¼š{analysis['avg']:.2f}")
    s.append(f"ğŸ¬ä»·æ ¼åŒºé—´ï¼š{analysis['min']:.2f} ~ {analysis['max']:.2f}")
    s.append(f"â¬†ï¸è·æœ€é«˜ï¼š{analysis['from_max_points']:.2f}ç‚¹ ({analysis['from_max_percent']:.1f}%)")
    s.append(f"â¬‡ï¸è·æœ€ä½ï¼š{analysis['from_min_points']:+.2f}ç‚¹ ({analysis['from_min_percent']:.1f}%)")
    s.append(f"ğŸ§®ç™¾åˆ†ä½ï¼š{analysis['percentile']:.1f}% (æ ·æœ¬ï¼š{analysis['sample_size']})")
    s.append(f"ğŸ“ˆè¶‹åŠ¿åˆ†æï¼š{trend_analysis['trend_description']}")
    s.append(f"ğŸ’µæŠ•èµ„å»ºè®®ï¼š{investment_advice['advice']}")
    s.append(f"ğŸ’¡æ“ä½œå»ºè®®ï¼š{investment_advice['action_desc']}")
    s.append(f"ğŸ“ç†ç”±ï¼š{investment_advice['reason']}")
    s.append(f"ğŸª™ä¼˜å…ˆçº§ï¼š{investment_advice['stars']}")
    s.append(f"ğŸ§¾è¯„åˆ†ï¼š{investment_advice['priority_score']:.1f}/10")
    return "\n".join(s)

# =================== å›¾è¡¨æ•°æ®ä¸é¡µé¢ç”Ÿæˆ ===================
def build_series_from_history():
    """è¯»å– price_history.txt -> å›¾è¡¨æ•°æ® payload"""
    if not os.path.exists(DATA_FILE):
        return {"updated_at": now_cst().strftime("%Y-%m-%d %H:%M:%S"), "x": [], "series": []}

    times = []
    values_by_cid = {cid: [] for cid in sorted(COMMERCE_MAP.keys())}
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        lines = [ln.strip() for ln in f.readlines() if ln.strip()]
    if len(lines) <= 1:
        return {"updated_at": now_cst().strftime("%Y-%m-%d %H:%M:%S"), "x": [], "series": []}

    for line in lines[1:]:
        parts = line.split()
        if len(parts) < 2 + len(COMMERCE_MAP):
            continue
        date_str, time_str = parts[0], parts[1]
        times.append(f"{date_str} {time_str}")
        for idx, cid in enumerate(sorted(COMMERCE_MAP.keys()), start=2):
            try:
                v = float(parts[idx])
            except Exception:
                v = None
            values_by_cid[cid].append(v)

    series = [{"id": cid, "name": COMMERCE_MAP[cid], "values": values_by_cid[cid]}
              for cid in sorted(COMMERCE_MAP.keys())]

    return {"updated_at": now_cst().strftime("%Y-%m-%d %H:%M:%S"), "x": times, "series": series}

def write_site_assets(chart_payload: dict, report_text: str):
    """
    ç”Ÿæˆç«™ç‚¹ï¼š
      - site/data.json
      - site/index.htmlï¼ˆå«â€œæœ€åæ›´æ–°â€ä¸â€œæŠ¥å‘Šâ€ï¼‰
      - site/price_history.txtï¼ˆéšè—é“¾æ¥ä½†ä¿ç•™æ–‡ä»¶ï¼‰
    """
    SITE_DIR.mkdir(parents=True, exist_ok=True)

    # data.json
    (SITE_DIR / "data.json").write_text(
        json.dumps(chart_payload, ensure_ascii=False),
        encoding="utf-8"
    )

    # å†å²æ–‡ä»¶ï¼ˆä¾¿äºåç»­æ‹‰å–ï¼‰
    if os.path.exists(DATA_FILE):
        shutil.copyfile(DATA_FILE, SITE_DIR / "price_history.txt")

    # index.html
    html = TEMPLATE_FILE.read_text(encoding="utf-8")
    html = html.replace("{{updated_at}}", chart_payload.get("updated_at", ""))
    html = html.replace("{{report}}", report_text or "")
    (SITE_DIR / "index.html").write_text(html, encoding="utf-8")

    print("âœ… å·²ç”Ÿæˆï¼šsite/index.html, site/data.json, site/price_history.txt")

# =================== ä¸»æµç¨‹ ===================
def run():
    if not HEADERS.get("token"):
        raise RuntimeError("ç¼ºå°‘ ARING_TOKEN ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ GitHub Secrets é…ç½®ã€‚")

    print("ğŸš€ æ‹‰å›å†å² â€¦")
    try_fetch_history_from_pages()

    print("ğŸš€ æ‹‰å–æœ€æ–°ä»·æ ¼ â€¦")
    r = requests.get(API_URL, headers=HEADERS, timeout=12)
    if r.status_code != 200:
        raise RuntimeError(f"è¯·æ±‚å¤±è´¥ï¼šHTTP {r.status_code}")
    payload = r.json()
    if "data" not in payload or not isinstance(payload["data"], list):
        raise RuntimeError("è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")

    # å½“å‰æ¡£ä½ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
    now = now_cst()
    current_date, time_slot = get_slot(now)  # â† è¿™é‡Œä¼šå¤„ç† 00:00-09:59 å½’å‰ä¸€å¤© 22:00


    # æ•´ç†å½“æœŸä»·æ ¼
    commerce_data = {}
    commerce_changes = {}
    for item in payload["data"]:
        cid = item.get("commerceId")
        if cid in COMMERCE_MAP:
            commerce_data[cid] = item.get("price", 0)
            commerce_changes[cid] = item.get("changeValue", 0)

    if not commerce_data:
        raise RuntimeError("æœªè·å–åˆ°æœ‰æ•ˆçš„ä»·æ ¼æ•°æ®")

    # è½½å…¥å†å²ï¼Œæ„å»ºæŠ¥å‘Š
    historical = load_historical_data()

    title = f"ğŸ“Š {current_date} {time_slot} ä»·æ ¼ç›‘æ§æŠ¥å‘Š\n{'='*40}\n"
    report_lines = [title]

    commerce_analysis = {}
    for cid in sorted(COMMERCE_MAP.keys()):
        if cid not in commerce_data:
            continue
        name = COMMERCE_MAP[cid]
        cur = commerce_data[cid]
        chg = commerce_changes.get(cid, 0.0)
        hist = historical.get(cid, [])

        pa = calculate_price_analysis(cur, hist)
        trend = calculate_trend_analysis(hist + [cur])
        adv = calculate_investment_advice(pa['percentile'], trend)

        block = format_analysis_text(name, cur, chg, pa, trend, adv)
        report_lines.append(block + "\n")

        commerce_analysis[cid] = {'name': name, 'priority_score': adv['priority_score']}

    # æ’è¡Œ
    report_lines.append(f"{'='*40}\nğŸ“ˆ æŠ•èµ„ä¼˜å…ˆçº§æ’è¡Œæ¦œ")
    for i, (cid, data) in enumerate(sorted(commerce_analysis.items(),
                                           key=lambda x: x[1]['priority_score'],
                                           reverse=True), 1):
        report_lines.append(f"{i}. {data['name']} ({data['priority_score']:.1f}åˆ†)")

    final_report = "\n".join(report_lines).strip()

    # è¿½åŠ å†å²
    save_data_row(current_date, time_slot, commerce_data)

    # ç”Ÿæˆå›¾è¡¨æ•°æ® + é¡µé¢
    chart_payload = build_series_from_history()
    chart_payload["updated_at"] = now.strftime("%Y-%m-%d %H:%M:%S")  # ç”¨åŒ—äº¬æ—¶é—´
    write_site_assets(chart_payload, report_text=final_report)

    print("ğŸ‰ å®Œæˆ")

if __name__ == "__main__":
    run()
